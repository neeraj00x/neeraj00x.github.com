<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>YOLOv8 Object Detection</title>

<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

<style>
  body {
    margin: 0;
    background: #0f172a;
    color: #e5e7eb;
    font-family: system-ui, Arial;
  }

  .app {
    max-width: 1100px;
    margin: auto;
    padding: 20px;
  }

  h2 {
    text-align: center;
    margin-bottom: 20px;
  }

  .controls {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center;
    margin-bottom: 15px;
  }

  button, input[type="file"] {
    background: #1e293b;
    color: #e5e7eb;
    border: 1px solid #334155;
    padding: 8px 14px;
    border-radius: 6px;
    cursor: pointer;
  }

  button:hover {
    background: #334155;
  }

  .viewer {
    display: flex;
    gap: 20px;
    justify-content: center;
    flex-wrap: wrap;
  }

  video, canvas {
    border: 1px solid #334155;
    border-radius: 6px;
    max-width: 100%;
  }

  .footer {
    text-align: center;
    margin-top: 15px;
    font-size: 13px;
    color: #94a3b8;
  }
</style>
</head>

<body>
<div class="app">

<h2>YOLOv8 Object Detection (Browser)</h2>

<div class="controls">
  <input id="uploadInput" type="file" accept="image/*"/>
  <button onclick="startCamera()">Start Camera</button>
  <button onclick="captureFromCamera()">Capture & Detect</button>
  <button id="model" onclick="selectModel()">Nano</button>
  <button onclick="downloadDetections()">Download detections (.txt)</button>
</div>

<div class="viewer">
  <video id="video" width="480" height="360" autoplay muted></video>
  <canvas></canvas>
</div>

<div class="footer">
  Client-side YOLOv8 inference â€¢ ONNX Runtime Web
</div>

</div>

<script>
/* ===================== STATE ===================== */
let lastDetections = [];
let lastImageFile = null;
let models = "yolov8n.onnx";

function selectModel() {
  const btn = document.getElementById("model");

  if (models === "yolov8n.onnx") {
    // Switch to Medium
    models = "yolov8s.onnx";
    btn.innerText = "Small";
  } else {
    // Switch back to Nano
    models = "yolov8n.onnx";
    btn.innerText = "Nano";
  } 
}

/* ===================== UPLOAD ===================== */
const input = document.getElementById("uploadInput");
input.addEventListener("change", async (event) => {
  lastImageFile = event.target.files[0];
  lastDetections = await detect_objects_on_image(lastImageFile);
  draw_image_and_boxes(lastImageFile, lastDetections);
});

/* ===================== CAMERA ===================== */
const video = document.getElementById("video");

async function startCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({ video:true });
    video.srcObject = stream;
}

async function captureFromCamera() {
  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = video.videoWidth;
  tempCanvas.height = video.videoHeight;
  tempCanvas.getContext("2d").drawImage(video, 0, 0);

  tempCanvas.toBlob(async (blob) => {
    lastImageFile = blob;
    lastDetections = await detect_objects_on_image(blob);
    draw_image_and_boxes(blob, lastDetections);
  }, "image/jpeg");
}

/* ===================== DRAW ===================== */
function draw_image_and_boxes(file, boxes) {
  const img = new Image();
  img.src = URL.createObjectURL(file);

  img.onload = () => {
    const canvas = document.querySelector("canvas");
    canvas.width = img.width;
    canvas.height = img.height;
    const ctx = canvas.getContext("2d");

    ctx.drawImage(img, 0, 0);
    ctx.lineWidth = 3;
    ctx.font = "16px Arial";

    boxes.forEach(([x1, y1, x2, y2, label, prob]) => {
      const text = `${label} ${(prob * 100).toFixed(1)}%`;

      ctx.strokeStyle = "#22c55e";
      ctx.fillStyle = "#22c55e";
      ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

      const textWidth = ctx.measureText(text).width;
      ctx.fillRect(x1, y1, textWidth + 8, 22);

      ctx.fillStyle = "#000";
      ctx.fillText(text, x1 + 4, y1 +17);
    });
  };
}

/* ===================== DOWNLOAD TXT ===================== */
function downloadDetections() {
  if (!lastDetections.length) {
    alert("No detections to download.");
    return;
  }

  let txt = "class, confidence, x1, y1, x2, y2\n";
  lastDetections.forEach(d => {
    txt += `${d[4]}, ${d[5].toFixed(4)}, ${d[0].toFixed(1)}, ${d[1].toFixed(1)}, ${d[2].toFixed(1)}, ${d[3].toFixed(1)}\n`;
  });

  const blob = new Blob([txt], { type: "text/plain" });
  const a = document.createElement("a");
  a.href = URL.createObjectURL(blob);
  a.download = "detections.txt";
  a.click();
}

/* ===================== MODEL PIPELINE (UNCHANGED) ===================== */
async function detect_objects_on_image(buf) {
  const [input, img_width, img_height] = await prepare_input(buf);
  const output = await run_model(input);
  return process_output(output, img_width, img_height);
}

async function prepare_input(buf) {
  return new Promise(resolve => {
    const img = new Image();
    img.src = URL.createObjectURL(buf);
    img.onload = () => {
      const canvas = document.createElement("canvas");
      canvas.width = 640;
      canvas.height = 640;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(img, 0, 0, 640, 640);

      const data = ctx.getImageData(0, 0, 640, 640).data;
      const r=[], g=[], b=[];
      for (let i=0;i<data.length;i+=4) {
        r.push(data[i]/255);
        g.push(data[i+1]/255);
        b.push(data[i+2]/255);
      }
      resolve([[...r,...g,...b], img.width, img.height]);
    };
  });
}

async function run_model(input) {
  const model = await ort.InferenceSession.create(models);
  const tensor = new ort.Tensor(Float32Array.from(input), [1,3,640,640]);
  const out = await model.run({ images: tensor });
  return out.output0.data;
}

/* ===================== POSTPROCESS (UNCHANGED) ===================== */
function process_output(output, w, h) {
  let boxes = [];
  for (let i=0;i<8400;i++) {
    const [cls, prob] = [...Array(80).keys()]
      .map(c => [c, output[8400*(c+4)+i]])
      .reduce((a,b)=>b[1]>a[1]?b:a,[0,0]);
    if (prob < 0.5) continue;

    const xc = output[i], yc = output[8400+i];
    const bw = output[2*8400+i], bh = output[3*8400+i];
    const x1 = (xc-bw/2)/640*w;
    const y1 = (yc-bh/2)/640*h;
    const x2 = (xc+bw/2)/640*w;
    const y2 = (yc+bh/2)/640*h;

    boxes.push([x1,y1,x2,y2,yolo_classes[cls],prob]);
  }

  boxes.sort((a,b)=>b[5]-a[5]);
  const res=[];
  while (boxes.length) {
    res.push(boxes[0]);
    boxes = boxes.filter(b => iou(res[res.length-1], b) < 0.7);
  }
  return res;
}

function iou(a,b){return inter(a,b)/(area(a)+area(b)-inter(a,b));}
function area(b){return (b[2]-b[0])*(b[3]-b[1]);}
function inter(a,b){
  const x1=Math.max(a[0],b[0]), y1=Math.max(a[1],b[1]);
  const x2=Math.min(a[2],b[2]), y2=Math.min(a[3],b[3]);
  return Math.max(0,x2-x1)*Math.max(0,y2-y1);
}

/* ===================== CLASSES ===================== */
const yolo_classes = [
'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat',
'traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat',
'dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack',
'umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball',
'kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket',
'bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple',
'sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair',
'couch','potted plant','bed','dining table','toilet','tv','laptop','mouse',
'remote','keyboard','cell phone','microwave','oven','toaster','sink',
'refrigerator','book','clock','vase','scissors','teddy bear','hair drier',
'toothbrush'
];
</script>

</body>
</html>
